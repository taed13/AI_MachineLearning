{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class LogisticRegression:\n",
    "    \n",
    "    def fit(self, X, y, lr = 0.001, epochs=10000, verbose=True, batch_size=1):\n",
    "        self.classes = np.unique(y)\n",
    "        y = (y==self.classes[1]) * 1\n",
    "        X = self.add_bias(X)\n",
    "        self.weights = np.zeros(X.shape[1])\n",
    "        self.loss = []\n",
    "        for i in range(epochs):\n",
    "            self.loss.append(self.cross_entropy(X,y))\n",
    "            if i % 1000 == 0 and verbose: \n",
    "                print('Iterations: %d - Error : %.4f' %(i, self.loss[i]))\n",
    "            idx = np.random.choice(X.shape[0], batch_size)\n",
    "            X_batch, y_batch =  X[idx], y[idx]\n",
    "            self.weights -= lr * self.get_gradient(X_batch, y_batch)\n",
    "        return self\n",
    "    \n",
    "    def get_gradient(self, X, y):\n",
    "        return -1.0 * (y - self.predict_(X)).dot(X) / len(X)\n",
    "    \n",
    "    def predict_(self, X):\n",
    "        return self.sigmoid(np.dot(X, self.weights))\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.predict_(self.add_bias(X))\n",
    "    \n",
    "    def sigmoid(self, z):\n",
    "        return 1.0/(1 + np.exp(-z))\n",
    "    \n",
    "    def predict_classes(self, X):\n",
    "        return self.predict_classes_(self.add_bias(X))\n",
    "\n",
    "    def predict_classes_(self, X):\n",
    "        return np.vectorize(lambda c: self.classes[1] if c>=0.5 else self.classes[0])(self.predict_(X))\n",
    "    \n",
    "    def cross_entropy(self, X, y):\n",
    "        p = self.predict_(X)\n",
    "        return (-1 / len(y)) * (y * np.log(p)).sum()\n",
    "\n",
    "    def add_bias(self,X):\n",
    "        return np.insert(X, 0, 1, axis=1)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return self.cross_entropy(self.add_bias(X), y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "def train_model(X, y, model):\n",
    "    model.fit(X, y, lr=0.1)\n",
    "    pre = model.predict_classes(X)\n",
    "    print('Accuracy :: ', accuracy_score(y, pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 0 - Error : 0.4621\n",
      "Iterations: 1000 - Error : 0.0028\n",
      "Iterations: 2000 - Error : 0.0021\n",
      "Iterations: 3000 - Error : 0.0013\n",
      "Iterations: 4000 - Error : 0.0012\n",
      "Iterations: 5000 - Error : 0.0010\n",
      "Iterations: 6000 - Error : 0.0007\n",
      "Iterations: 7000 - Error : 0.0006\n",
      "Iterations: 8000 - Error : 0.0005\n",
      "Iterations: 9000 - Error : 0.0005\n",
      "Accuracy ::  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "X, y = load_iris(return_X_y=True)\n",
    "lr = LogisticRegression()\n",
    "train_model(X,(y !=0 )*1, lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "plt.plot(np.arange(len(lr.loss)), lr.loss)\n",
    "plt.title(\"Development of cost over training\")\n",
    "plt.xlabel(\"Number of iterations\")\n",
    "plt.ylabel(\"Cost\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0559ed34a2889daaee4bf7da49a717c30f35a2c693218d799055d485db57fcb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
